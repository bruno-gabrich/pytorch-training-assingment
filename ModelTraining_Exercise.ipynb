{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a56c82-3273-4d86-a3a6-c6d24f13dc54",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px;\">***Binary Classification Model - Training Exercise***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba8cb6",
   "metadata": {},
   "source": [
    "### Exercise: Train a Neural Network using PyTorch\n",
    "\n",
    "This exercise is about implementing the **training loop** for a simple binary classifier using PyTorch. The Neural Network is consisted of **4** neurons at the input layer, **64** neurons at the hidden layer and a single output neuron. The chosen loss function is `BCELoss()` and `Adam` is used as an optimizer.\n",
    "\n",
    "The dataset, model, optimizer, and loss function are already provided. Your job is:\n",
    "\n",
    "- Run the training loop for a fixed number of epochs. \n",
    "- Compute the training loss and test loss.  \n",
    "- Evaluate accuracy at each epoch.  \n",
    "- Achieve satisfactory accuracy ~95%.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- The dataset comes from the iris dataset. \n",
    "- It is consisted of **4** features and a binary label (**0** or **1**).\n",
    "- Originally `iris.target` is consisted of 3 unique values (**0**, **1**, **2**). To guarantee binary labels we only use the first **100** data points.\n",
    "- Features are parsed to varibale `X` and labels are parsed to varible `y`.\n",
    "\n",
    "### What youâ€™ll learn\n",
    "\n",
    "- How to structure a clean PyTorch training loop  \n",
    "- Using `.train()` and `.eval()` modes properly  \n",
    "- Disabling gradient tracking with `torch.no_grad()`  \n",
    "- Tracking and plotting losses and accuracy over time\n",
    "\n",
    "### Python libraries\n",
    "\n",
    "- **PyTorch** for modeling and training  \n",
    "- **scikit-learn** for preprocessing  \n",
    "- **matplotlib** for visualizations  \n",
    "- **tqdm** for progress tracking  \n",
    "\n",
    "### Instructions\n",
    "\n",
    "- This assignment is consisted of **13** cells. \n",
    "- You should execute each cell in sequence.\n",
    "- The Neural Network model is defined in cell number **7**. \n",
    "- **Your code should be inserted in cell number 9**. \n",
    "- You should not change content of other cells, for example modifying the `learning rate` value.\n",
    "- Make sure you record values for `test_losses`, `train_losses`, `accuracies` for each `epoch`.\n",
    "- `Sigmoid` function outputs continuous values between **0** and **1**. You must transform this output to binary values (**0** or **1**) in order to compare model outputs against labels.\n",
    "- Accuracy values must be between **0** and **1**.\n",
    "- In order to visualize your results you can plot losses and accuracies running cell **10** and **11** respectively.\n",
    "- Your grade can be obtained running cell **12**.\n",
    "- The solution for this work can be found at the last cell. \n",
    "- Please, only check solution after you have worked and debugged your own code.\n",
    "\n",
    "### Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3775e-f67b-4509-9c69-44b84604375b",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***1. Importing torch, sklearn, matplotlib and tqdm libraries***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc260b2-90a6-4316-b610-1665f2814d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbc18e-ff2d-4382-b8b6-d785be7ca6ad",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***2. Importing data***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883f5b5-6fdc-41b7-aadc-8b00a8b17bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "#Extract the features and target variables\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X = X[0:100, :]\n",
    "y = y[0:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7a3c6-7cff-446e-95ca-d7fb4b2b9a9e",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***3. Splitting Data into Training and Testing***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395be24-b7b8-491a-a8dd-f086ebaa94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#random_state=42 guarantees the split will be always the same\n",
    "#stratify=y maintains proportion of labels for train and test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84f4b9-085c-459d-91db-b02b24427301",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***4. Verifying dimensions of train and test data.***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a92890-d181-4d87-b532-2585e53baa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f'X_train shape: {X_train.shape}')\n",
    "display(f'y_train shape: {y_train.shape}')\n",
    "display(f'X_test shape: {X_test.shape}')\n",
    "display(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa17cd-2f5e-43df-9c90-5a08906b0142",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***5. Normalizing Data***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7bde57-21cd-45c7-8a01-139da88ba4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5855b-3721-404b-8219-1d08fdb88619",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***6. Converting data from numpy to tensor***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05714d-bc8d-4440-90d6-18930bd4727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5b8b5-3117-4294-8d69-4ca839d7c2fd",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***7. Building the Neural Network model***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e54f18-a382-4e14-93ad-3e7b08eb8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "    \"\"\"This class defines the neural network for the classification model.\"\"\"\n",
    "    def __init__(self, input_units, hidden_units, output_units):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_units, hidden_units) # linear function defined with 4 inputs and  64 outputs.\n",
    "        self.fc2 = nn.Linear(hidden_units, output_units) # linear function defined with 64 inputs and 1 output.\n",
    "        self.sigmoid = nn.Sigmoid() # sigmoid function to guarantee positive output values.\n",
    "\n",
    "    def forward(self, x): # forward propagation of the Neural Network.\n",
    "        x = self.fc1(x) # first Linear operation called.\n",
    "        x = torch.relu(x) # Relu as activation\n",
    "        x = self.fc2(x) # second Linear operation called.\n",
    "        x = self.sigmoid(x) # sigmoid function applied (values between 0 and 1).\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ClassificationNet(input_units=4, hidden_units=64, output_units=1) # nn consisting of 4 inputs, 1 hidden layer of 64 neurons and a single output neuron.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd3c34-9436-4e2d-9b54-654339ccbff1",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***8. Defining Binary Cross Entropy as the Loss function and Adam as the chosen optimizer***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7ef3a-70d7-48d6-a322-28d19320a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss() # binary cross entropy as loss function to train the model\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4) # adam as an optimizer, learning rate of 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7482fa",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***9. Training Assignment***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a9f68-d125-4d7c-a34c-ff8e041f5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_assignment():\n",
    "    \"\"\"This function trains the model\"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracies = []\n",
    "    \"\"\"epochs = Choose the proper number of epochs.\"\"\" \n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        #Training Phase\n",
    "        \n",
    "        \"\"\"Your code should be inserted here.\"\"\"\n",
    "        \n",
    "  \n",
    "\n",
    "\n",
    "        \n",
    "        #Evaluation Phase\n",
    "        accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            \"\"\"Your code should be inserted here.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "  \n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {loss.item():.4f}, Test Loss = {loss_test.item():.4f}, Accuracy = {accuracy:.4f}\")\n",
    "    return train_losses, test_losses, accuracies, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf82843-eeaf-4d3e-953e-126e8385e432",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***9. Start Training the Model***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92fc3c-1fcd-4c35-a08c-70ef88039c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses, accuracies, epochs = training_assignment() # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3ad06-11e6-4a27-bc8e-7a339b4199bd",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***10. Plot Train and Test Losses***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d367c-3870-4c32-b3f8-a24bbc0d5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2233d-842f-4f05-8554-d4a22a5e0439",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***11. Plot Model Accuracy***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5c998-7163-4741-96df-359ecf534894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(accuracies, label='Accuracy', linestyle=':', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f0396-294e-4e3e-8e92-00c333d448cc",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***12. Grading***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a0471-cb14-44ca-8b1b-638ab6a3891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class GradedModelTrainingTest(unittest.TestCase):\n",
    "    max_grade = 100\n",
    "    feedback = []\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.train_loss, cls.test_loss, cls.accuracy, cls.epochs = train_losses, test_losses, accuracies, epochs\n",
    "        GradedModelTrainingTest.grade = 0\n",
    "    def test_output_lengths(self):\n",
    "        try:\n",
    "            self.assertEqual(len(self.train_loss), self.epochs)\n",
    "            self.assertEqual(len(self.test_loss), self.epochs)\n",
    "            self.assertEqual(len(self.accuracy), self.epochs)\n",
    "            GradedModelTrainingTest.grade += 20\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Output lists do not match the number of epochs.\")\n",
    "\n",
    "    def test_train_loss_is_float_list(self):\n",
    "        try:\n",
    "            self.assertTrue(all(isinstance(l, float) for l in self.train_loss))\n",
    "            GradedModelTrainingTest.grade += 10\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Train loss must contain only float values.\")\n",
    "\n",
    "    def test_accuracy_between_0_and_1(self):\n",
    "        try:\n",
    "            self.assertTrue(all(0.0 <= a <= 1.0 for a in self.accuracy))\n",
    "            GradedModelTrainingTest.grade += 20\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Accuracy values must be between 0.0 and 1.0.\")\n",
    "\n",
    "    def test_train_loss_decreases1(self):\n",
    "        try:\n",
    "            self.assertLessEqual(self.train_loss[int(len(self.train_loss) / 2)], self.train_loss[0])\n",
    "            GradedModelTrainingTest.grade += 10\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Train loss did not decrease over time.\")\n",
    "\n",
    "    def test_train_loss_decreases2(self):\n",
    "        try:\n",
    "            self.assertLessEqual(self.train_loss[-1], self.train_loss[int(len(self.train_loss) / 2)])\n",
    "            GradedModelTrainingTest.grade += 10\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Train loss did not decrease over time.\")\n",
    "\n",
    "    def test_accuracy_value_80(self):\n",
    "        try:\n",
    "            self.assertTrue(self.accuracy[-1] > 0.8)\n",
    "            GradedModelTrainingTest.grade += 5\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Model accuracy is less than 80 percent. Improve Model.\")\n",
    "\n",
    "    def test_accuracy_value_90(self):\n",
    "        try:\n",
    "            self.assertTrue(self.accuracy[-1] > 0.9)\n",
    "            GradedModelTrainingTest.grade += 10\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Model accuracy is less than 90 percent. Improve Model.\")\n",
    "\n",
    "    def test_accuracy_value_95(self):\n",
    "        try:\n",
    "            self.assertTrue(self.accuracy[-1] > 0.95)\n",
    "            GradedModelTrainingTest.grade += 15\n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.feedback.append(\"Model accuracy is less than 95 percent. Improve Model.\")\n",
    "\n",
    "    def test_initial_loss(self):\n",
    "        try:\n",
    "            self.assertTrue(self.train_loss[0] > 0.5) \n",
    "        except AssertionError:\n",
    "            GradedModelTrainingTest.grade -= 100\n",
    "            GradedModelTrainingTest.feedback.append(\"Make sure you are re-initializing model parameters (cells 7, 8) before training.\")\n",
    "    \n",
    "\n",
    "# Run the test suite and print grade\n",
    "def grade_unittest():\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(GradedModelTrainingTest)\n",
    "    runner = unittest.TextTestRunner(verbosity=0)\n",
    "    runner.run(suite)\n",
    "\n",
    "    print(f\"Final Score: {GradedModelTrainingTest.grade}/{GradedModelTrainingTest.max_grade}\")\n",
    "    if GradedModelTrainingTest.feedback:\n",
    "        print(\"Feedback:\")\n",
    "        for msg in GradedModelTrainingTest.feedback:\n",
    "            print(\" -\", msg)\n",
    "    else:\n",
    "        print(\"All checks passed. Model accuracy higher than 95%!\")\n",
    "\n",
    "\n",
    "grade_unittest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9521f",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px;\">***13. Solution***.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de6269-1d87-4f43-ab92-e2945b5603bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_solution():\n",
    "    \"\"\"This function trains the newly created model\"\"\"\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracies = [] \n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        #Training Phase\n",
    "        model.train()\n",
    "        optimizer.zero_grad() #optimizer parameters are set to zero.\n",
    "        train_output = model(X_train) #forward computation of the NN.\n",
    "        loss = criterion(train_output.squeeze(dim=1), y_train) #Loss function computation\n",
    "        loss.backward() #back propogation is executed.\n",
    "        optimizer.step() #parameters are updated.\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        #Evaluation Phase\n",
    "        accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_output = model(X_test) #forward propagation.\n",
    "            loss_test = criterion(test_output.squeeze(dim=1), y_test) #Loss function computed using test batch\n",
    "            test_losses.append(loss_test.item())\n",
    "\n",
    "            predictions = (test_output.squeeze(dim=1) > 0.5).float() #predictions are computed following the procedeure: if testout> 0.5, prediction[epoch] = 1, else prediction[epoch] = 0\n",
    "            correctness = (predictions == y_test).sum().item() #Check all correct values and sum it.\n",
    "            accuracy = correctness / y_test.size(0) #accuracy computation\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "    #if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {loss.item():.4f}, Test Loss = {loss_test.item():.4f}, Accuracy = {accuracy:.4f}\")\n",
    "    return train_losses, test_losses, accuracies, epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
